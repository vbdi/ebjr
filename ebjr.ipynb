{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "394a9ec0",
   "metadata": {},
   "source": [
    "# EBJR: Energy-Based Joint Reasoning for Adaptive Inference (BMVC2021)\n",
    "##### This notebook contains the implmenetation of the paper 'EBJR: Energy-Based Joint Reasoning for Adaptive Inference' published in BMVC2021."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c63d275",
   "metadata": {},
   "source": [
    "![](https://modelarts-cnnorth1-market-dataset.obs.cn-north-1.myhuaweicloud.com/example-apps/ebjr/images/ebjr_framework.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca0f5da",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "##### - Smaller (shallower) models -> lower prediction accuracy, but faster\n",
    "##### - Larger (deeper) models -> higher prediction accuracy, but slower\n",
    "##### - Combine Small (called Student) + Large (called Teacher)\n",
    "##### - Majority processed by Student -> high accuracy and/or low latency\n",
    "##### - Joint inference via an energy-based Router: to decide which model to use for each input data\n",
    "##### - Inference-time trade-off between latency and accuracy\n",
    "##### - Applicable to any pre-trained model, and different computer vision tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e5b7ac",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "##### In order to run this code, torch==1.7.1 and torchvision==0.8.2 packages are required, which can be installed using the following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29552d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch==1.7.1\n",
    "!pip install torchvision==0.8.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851dc17e",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d05b83b",
   "metadata": {},
   "source": [
    "#### Download Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d86889",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://modelarts-cnnorth1-market-dataset.obs.cn-north-1.myhuaweicloud.com/example-apps/ebjr/code.zip\n",
    "!unzip -qo code.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8c7a01",
   "metadata": {},
   "source": [
    "##### EBJR over CIFAR-10 with DenseNet-52-6 (as Student) and DenseNet-64-12 (as Teacher):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e5c975e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing dataset cifar10\n",
      "\n",
      "==> creating model 'densenet'\n",
      "\n",
      "==> creating teacher model 'densenet'\n",
      "\n",
      "    Total params: 0.07M\n",
      "\n",
      "    Total teacher params: 0.37M\n",
      "\n",
      "==> Resuming from checkpoint..\n",
      "\n",
      "---------------------\n",
      "\n",
      "Student: \n",
      "\n",
      "Params: 0.07M\n",
      "\n",
      "FLOPs (10^8): 0.54754784\n",
      "\n",
      "---------------------\n",
      "\n",
      "Teacher: \n",
      "\n",
      "Params: 0.37M\n",
      "\n",
      "FLOPs (10^8): 2.92380404\n",
      "\n",
      "\n",
      "\n",
      "Evaluation only\n",
      "\n",
      "\u001b[KProcessing |################################| (10000/10000) Data: 0.001s | Batch: 0.012s | Total: 0:02:02 | ETA: 0:00:01 | top1:  94.7700 | top5:  99.8000\n",
      "\n",
      "---------------------\n",
      "\n",
      "#Samples: 10000\n",
      "\n",
      "Samples Processed by Student (%): 72.03\n",
      "\n",
      "Samples Processed by Teacher (%): 27.969999999999995\n",
      "\n",
      "Accuracy (%): 94.77\n",
      "\n",
      "FLOPs (10^8): 1.3653358299879998\n",
      "\n",
      "Average Latency (s): 0.010832044768333436\n",
      "\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!python ebjr.py --evaluate --dataset cifar10 --arch densenet --depth 52 --growthRate 6 --tarch densenet --tdepth 64 --tgrowthRate 12 --resume checkpoints/cifar10/densenet-bc-52-6/model_best.pth.tar --tresume checkpoints/cifar10/densenet-bc-64-12/model_best.pth.tar --router_threshold 2.46"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd40471c",
   "metadata": {},
   "source": [
    "##### EBJR over CIFAR-100 with DenseNet-58-6 (as Student) and DenseNet-88-8 (as Teacher):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3389a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing dataset cifar100\n",
      "\n",
      "==> creating model 'densenet'\n",
      "\n",
      "==> creating teacher model 'densenet'\n",
      "\n",
      "    Total params: 0.09M\n",
      "\n",
      "    Total teacher params: 0.30M\n",
      "\n",
      "==> Resuming from checkpoint..\n",
      "\n",
      "---------------------\n",
      "\n",
      "Student: \n",
      "\n",
      "Params: 0.09M\n",
      "\n",
      "FLOPs (10^8): 0.64281872\n",
      "\n",
      "---------------------\n",
      "\n",
      "Teacher: \n",
      "\n",
      "Params: 0.30M\n",
      "\n",
      "FLOPs (10^8): 2.14001928\n",
      "\n",
      "\n",
      "\n",
      "Evaluation only\n",
      "\n",
      "\u001b[KProcessing |################################| (10000/10000) Data: 0.001s | Batch: 0.016s | Total: 0:02:40 | ETA: 0:00:01 | top1:  74.7900 | top5:  93.6900\n",
      "\n",
      "---------------------\n",
      "\n",
      "#Samples: 10000\n",
      "\n",
      "Samples Processed by Student (%): 56.730000000000004\n",
      "\n",
      "Samples Processed by Teacher (%): 43.269999999999996\n",
      "\n",
      "Accuracy (%): 74.79\n",
      "\n",
      "FLOPs (10^8): 1.568805062456\n",
      "\n",
      "Average Latency (s): 0.01464376654624939\n",
      "\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!python ebjr.py --evaluate --dataset cifar100 --arch densenet --depth 58 --growthRate 6 --tarch densenet --tdepth 88 --tgrowthRate 8 --resume checkpoints/cifar100/densenet-bc-58-6/model_best.pth.tar --tresume checkpoints/cifar100/densenet-bc-88-8/model_best.pth.tar --router_threshold 4.6195"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8f8b0b",
   "metadata": {},
   "source": [
    "## Arguments\n",
    "##### - 'dataset': cifar10, cifar100, or imagenet\n",
    "##### - 'arch': the network architecture for Student\n",
    "##### - 'depth': the model depth for Student\n",
    "##### - 'growthRate': the growth rate for for Student (if tarch is resnet or densenet)\n",
    "##### - 'tarch': the network architecture for Teacher\n",
    "##### - 'tdepth': the model depth for Teacher (if tarch is resnet or densenet)\n",
    "##### - 'tgrowthRate': the growth rate for for Teacher (if arch is densenet)\n",
    "##### - 'resume': the checkpoint path for Student\n",
    "##### - 'tresume': the checkpoint path for Teacher\n",
    "##### - 'router_threshold': the router threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f36b18f",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b359f4b",
   "metadata": {},
   "source": [
    "### Image Classification\n",
    "##### - Average of ~2X less FLOPs compared to Teacher\n",
    "##### - Average of ~1.5X less latency compared to Teacher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f919636f",
   "metadata": {},
   "source": [
    "![](https://modelarts-cnnorth1-market-dataset.obs.cn-north-1.myhuaweicloud.com/example-apps/ebjr/images/table.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67ef61e",
   "metadata": {},
   "source": [
    "#### Trade-off curves compared with SOTA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98643302",
   "metadata": {},
   "source": [
    "![](https://modelarts-cnnorth1-market-dataset.obs.cn-north-1.myhuaweicloud.com/example-apps/ebjr/images/ic-curves.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e531e5",
   "metadata": {},
   "source": [
    "### Object Detection\n",
    "##### With EfficientDet-D0 (as Student) and EfficientDet-D4 (as Teacher) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b76b97",
   "metadata": {},
   "source": [
    "![](https://modelarts-cnnorth1-market-dataset.obs.cn-north-1.myhuaweicloud.com/example-apps/ebjr/images/od.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687c595a",
   "metadata": {},
   "source": [
    "## Specialized EBJR\n",
    "#####  - Assumption: majority of data (e.g., 70%) belongs to a small subset of popular classes \n",
    "#####  - Train and specialize the Student model targeting specific/popular classes\n",
    "#####  - Highly accurate Student predictions for the majority of input data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5642b78",
   "metadata": {},
   "source": [
    "## Demo video for Specialized EBJR \n",
    "##### The following video demonstrates the Specialized EBJR with Top-50+1 scenario over OID dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "084cd8ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video width=\"1280\" controls>\n",
       "    <source src=\"https://modelarts-cnnorth1-market-dataset.obs.cn-north-1.myhuaweicloud.com/example-apps/ebjr/Demo.mp4\" type=\"video/mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<video width=\"1280\" controls>\n",
    "    <source src=\"https://modelarts-cnnorth1-market-dataset.obs.cn-north-1.myhuaweicloud.com/example-apps/ebjr/Demo.mp4\" type=\"video/mp4\">\n",
    "</video>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce31751a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "imageInfo": {
   "id": "e1a07296-22a8-4f05-8bc8-e936c8e54099",
   "name": "pytorch1.4-cuda10.1-cudnn7-ubuntu18.04"
  },
  "kernelspec": {
   "display_name": "python-3.7.10",
   "language": "python",
   "name": "python-3.7.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "shareInfo": {
   "id": "5c5afe29-09ea-4558-acf4-52f0570d5af9",
   "url": "https://authoring-modelarts-cnnorth4.huaweicloud.com/console/lab?share-url-b64=aHR0cHM6Ly9ub3RlYm9va3NoYXJlLm9icy5jbi1ub3J0aC00Lm15aHVhd2VpY2xvdWQuY29tLzBlNDhmNjEyNGFmZDQwNmU5ZmViZTJjZDMyOTY3NzM2L2VianIuaXB5bmI%3D"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
